{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Conv2D, Dense, MaxPooling2D , Flatten\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from collections import deque\n",
    "from keras.optimizers import Adam\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('SpaceInvaders-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac =env.action_space.sample()\n",
    "o,r,d,i = env.step(1)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dqn = DQN(( 210 , 160, 3), 6)\n",
    "dqn.policy_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stato = o.reshape((1,210,160,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=dqn.policy_net.predict(stato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1000):\n",
    "    env.render()\n",
    "    ac =env.action_space.sample()\n",
    "    o,r,d,i = env.step(ac)\n",
    "    if d:\n",
    "        env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con la funzione action_space riusciamo a trovare lo spazio delle azioni \n",
    "print (env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con la funzione observation_space, invece, troviamo lo spazio delle osservazioni, in questo caso le dimensioni in pixel della\n",
    "# nostra simulazione\n",
    "print (env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, input_shape, output_shape, discount=0.99, update_target_every=10, memory_size=2000):\n",
    "        self.input_shape=input_shape\n",
    "        self.output_shape=output_shape\n",
    "        self.discount=discount\n",
    "        self.update_target_every=update_target_every\n",
    "        self.policy_net=self.create_model()\n",
    "        self.memory=deque(maxlen=memory_size)\n",
    "        self.target_counter=0 \n",
    "    \n",
    "    def create_model(self):\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(input_shape=self.input_shape, filters=32, kernel_size=(7,7), strides=(5,5), padding=\"valid\", \n",
    "                        activation=\"relu\", use_bias=True,))\n",
    "        model.add(Conv2D(filters=16, kernel_size=(5,5), strides=(4,4), padding=\"valid\", \n",
    "                        activation=\"relu\", use_bias=True,))\n",
    "        model.add(Conv2D(filters=8, kernel_size=(3,3), strides=(2,2), padding=\"valid\", \n",
    "                        activation=\"relu\", use_bias=True,))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation=\"relu\"))\n",
    "        model.add(Dense(self.output_shape, activation=\"softmax\"))\n",
    "        adm=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        model.compile(loss=\"mse\", optimizer=adm, metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \n",
    "    def get_action (self,state):\n",
    "        action_prob= self.policy_net.predict(state)\n",
    "        return action_prob\n",
    "        \n",
    "       \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
